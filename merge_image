import cv2
import numpy as np
import os
os.chdir("<path>")

back_ground = "background.jpg"

#顔認識、いらない
#face_cascade_path = r"C:\Users\user\Desktop\opencv-master\data\haarcascades\haarcascade_frontalface_default.xml"
#eye_cascade_path = r"C:\Users\user\Desktop\opencv-master\data\haarcascades\haarcascade_eye.xml"
#face_cascade = cv2.CascadeClassifier(face_cascade_path)
#eye_cascade = cv2.CascadeClassifier(eye_cascade_path)

ratio = 0.05

def cv_fourcc(c1, c2, c3, c4):
    return (ord(c1) & 255) + ((ord(c2) & 255) << 8) + \
        ((ord(c3) & 255) << 16) + ((ord(c4) & 255) << 24)

#前面の明るさ調節
gamma = 0.6
gamma_cvt = np.zeros((256, 1), dtype='uint8')
for i in range(256):
    gamma_cvt[i][0] = 255 * (float(i)/255)**(1.0*gamma)

threshold = 120
if __name__ == '__main__':
    # 定数定義
    ESC_KEY = 27     # Escキー
    INTERVAL= 33     # 待ち時間
    FRAME_RATE = 30  # fps

    ORG_WINDOW_NAME = "org"
    #GAUSSIAN_WINDOW_NAME = "gaussian"
    #GAUSSIAN_FILE_NAME = "gaussian.avi"
    
    #パソコンのカメラ：0
    DEVICE_ID = 0

    # カメラ映像取得
    cap = cv2.VideoCapture(DEVICE_ID)
    
    # 保存ビデオファイルの準備
    
    end_flag, c_frame = cap.read()
    #c_frame = (c_frame*0.9).astype(np.int32)
    height, width, channels = c_frame.shape
    rec = cv2.VideoWriter(GAUSSIAN_FILE_NAME, \
                          cv_fourcc('X', 'V', 'I', 'D'), \
                          FRAME_RATE, \
                          (width, height), \
                          True)
    

    # ウィンドウの準備
    #cv2.namedWindow(ORG_WINDOW_NAME)
    #cv2.namedWindow(GAUSSIAN_WINDOW_NAME)
    #cv2.namedWindow("OTSU")
    cv2.namedWindow("MERGED")
    cv2.namedWindow("img_1")
    #cv2.namedWindow("binary")
    #cv2.namedWindow("mask")
    #cv2.namedWindow("img_2")
    cv2.namedWindow("img_3")
    #cv2.namedWindow("img_4")
    
    # 変換処理ループ
    while end_flag == True:
        # ガウシアン平滑化
        #g_frame = cv2.GaussianBlur(c_frame, (15, 15), 10)
        
        img_1 = c_frame  # 前景になる画像の読み出し
        img_2 = cv2.imread(back_ground)   #  背景になる画像の読み出し
        w1, h1  = img_1.shape[:2]
        img_2 = cv2.resize(img_2 , (int(h1), int(w1)))

        img_1_gray = cv2.cvtColor(img_1, cv2.COLOR_BGR2GRAY) # 前景画像をグレースケール変換
        
        ret, img_1_binary= cv2.threshold(img_1_gray, threshold, 255, cv2.THRESH_BINARY)  # 閾値で二値化しマスク画像を作成(人物を黒に)
        mask_bgr = cv2.cvtColor(img_1_binary, cv2.COLOR_GRAY2BGR)  # ndarrayの型合わせのためGRAY→BGRに変換
        
        ret, mask_bgr_bin = cv2.threshold(img_1_gray, threshold, 1, cv2.THRESH_BINARY) #img4のマスク作成、人物が黒になるように
        mask_bgr_bin = cv2.cvtColor(mask_bgr_bin, cv2.COLOR_GRAY2BGR)
        
        ret, mask_bgr_bin_inv = cv2.threshold(img_1_gray, threshold, 1, cv2.THRESH_BINARY_INV) #img3のマスク作成、人物の背景黒
        mask_bgr_bin_inv = cv2.cvtColor(mask_bgr_bin_inv, cv2.COLOR_GRAY2BGR)
        
        img_3 = img_1 * mask_bgr_bin_inv  # 前景画像に反転01マスクを掛け人物だけ抜き出す(それ以外は黒)
        img_3 = cv2.LUT(img_3, gamma_cvt)

        img_4 = img_2 * mask_bgr_bin  # 背景画像に1マスクを掛け人物以外の部分を抜き出す(それ以外は黒)

        img_merged = img_3 + img_4  # 前景、背景を併せる
        
        n = 1.5　　#出力動画の倍率
        x1, x2 = img_merged.shape[:2]
        img_merged = cv2.resize(img_merged, (int(x2*n), int(x1*n)))
        
        """　
        顔認識で遊べる、いらない
        img = img_merged
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)
        for x, y, w, h in faces:
            cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
            face = img[y: y + h, x: x + w] 
            face = (face*10).astype(np.int32)
            face_gray = gray[y: y + h, x: x + w]
            eyes = eye_cascade.detectMultiScale(face_gray)
            for (ex, ey, ew, eh) in eyes:
                cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)
        
        for x, y, w, h in faces:
            small = cv2.resize(img[y: y + h, x: x + w], None, fx=ratio, fy=ratio, interpolation=cv2.INTER_NEAREST)
            img[y: y + h, x: x + w] = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)
        """
        
        # フレーム表示
        
        #cv2.imshow(ORG_WINDOW_NAME, c_frame)
        cv2.imshow("img_1", img_1)
        #cv2.imshow("binary", mask_bgr)
        #cv2.imshow("img_2", img_2)
        #cv2.imshow("img_3", img_3)
        #cv2.imshow("img_4", img_4)
        #cv2.imshow(GAUSSIAN_WINDOW_NAME, g_frame)
        #cv2.imshow("OTSU", dst)
        cv2.imshow("MERGED", img_merged)


        # Escキーで終了
        key = cv2.waitKey(INTERVAL)
        if key == ESC_KEY:
            break

        # 次のフレーム読み込み
        end_flag, c_frame = cap.read()

    # 終了処理
    cv2.destroyAllWindows()
    cap.release()
    rec.release()
